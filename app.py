import streamlit as st
import openai
import os
import requests
import json
import asyncio
import edge_tts
from pydub import AudioSegment
from tempfile import NamedTemporaryFile

# --- é é¢è¨­å®š ---
st.set_page_config(
    page_title="Podcast AI Studio",
    page_icon="ğŸ™ï¸",
    layout="wide"  # æ”¹ç‚ºå¯¬ç‰ˆé¢ï¼Œè¦–è¦ºæ›´é–‹é—Š
)

# --- CSS å„ªåŒ– 
st.markdown("""
<style>
    .stChatInput {position: fixed; bottom: 30px;}
    .main-header {font-size: 2.5rem; color: #FF4B4B; font-weight: 700;}
    .sub-header {font-size: 1.2rem; color: #555;}
    div.stButton > button:first-child {
        background-color: #FF4B4B;
        color: white;
        border-radius: 10px;
        height: 50px;
        width: 100%;
        font-size: 18px;
    }
</style>
""", unsafe_allow_html=True)

# --- åˆå§‹åŒ– Session State
if 'script_data' not in st.session_state:
    st.session_state.script_data = None
if 'audio_file' not in st.session_state:
    st.session_state.audio_file = None

# --- å´é‚Šæ¬„ï¼šè¨­å®šå€ ---
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/2628/2628834.png", width=100)
    st.title("âš™ï¸ å·¥ä½œå®¤è¨­å®š")
    
    openai_api_key = st.text_input("OpenAI API Key", type="password")
    if openai_api_key:
        openai.api_key = openai_api_key

    st.markdown("---")
    st.subheader("ğŸ—£ï¸ è²éŸ³é¸è§’")
    
    # è®“ä½¿ç”¨è€…é¸æ“‡è²éŸ³
    voice_options = {
        "å°ç£ç”·è² (Yunxi)": "zh-TW-YunxiNeural",
        "å°ç£å¥³è² (HsiaoChen)": "zh-TW-HsiaoChenNeural",
        "ç¾åœ‹ç”·è² (Guy)": "en-US-GuyNeural",
        "ç¾åœ‹å¥³è² (Aria)": "en-US-AriaNeural"
    }
    
    alex_voice_name = st.selectbox("ä¸»æŒäºº Alex (å°ˆå®¶)", options=list(voice_options.keys()), index=0)
    jamie_voice_name = st.selectbox("ä¾†è³“ Jamie (å°ç™½)", options=list(voice_options.keys()), index=1)
    
    alex_voice = voice_options[alex_voice_name]
    jamie_voice = voice_options[jamie_voice_name]

# --- æ ¸å¿ƒåŠŸèƒ½
def get_web_content(url):
    jina_url = f"https://r.jina.ai/{url}"
    try:
        response = requests.get(jina_url)
        return response.text
    except Exception as e:
        return None

def generate_script(text):
    system_prompt = """
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ Podcast è…³æœ¬ä½œå®¶ã€‚è«‹æ ¹æ“šæä¾›çš„æ–‡ç« å…§å®¹ï¼Œå¯«å‡ºä¸€æ®µå°è©±è…³æœ¬ã€‚
    
    è§’è‰²ï¼š
    1. Alex: å°ˆå®¶ï¼Œç†æ€§æ²ˆç©©ã€‚
    2. Jamie: å¥½å¥‡å°ç™½ï¼Œå¹½é»˜æ´»æ½‘ã€‚

    æ ¼å¼è¦å®šï¼š
    å‹™å¿…å›å‚³ JSON ç‰©ä»¶ï¼ŒåŒ…å« "dialogue" åˆ—è¡¨ã€‚
    ç¯„ä¾‹ï¼š{"dialogue": [{"speaker": "Alex", "text": "..."}, {"speaker": "Jamie", "text": "..."}]}
    """
    try:
        client = openai.Client(api_key=openai_api_key)
        response = client.chat.completions.create(
            model="gpt-4o", 
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"æ–‡ç« å…§å®¹ï¼š\n{text[:10000]}"} 
            ],
            response_format={"type": "json_object"}
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        st.error(f"LLM Error: {e}")
        return None

async def text_to_speech_edge(text, voice, output_file):
    communicate = edge_tts.Communicate(text, voice)
    await communicate.save(output_file)

def process_audio(script_json, v_alex, v_jamie):
    combined = AudioSegment.empty()
    
    # è™•ç† JSON æ ¼å¼å®¹éŒ¯
    if isinstance(script_json, dict) and "dialogue" in script_json:
        data = script_json["dialogue"]
    elif isinstance(script_json, list):
        data = script_json
    else:
        # å–®ä¸€ç‰©ä»¶å®¹éŒ¯
        data = [script_json]

    total = len(data)
    my_bar = st.progress(0)
    temp_files = []

    for i, line in enumerate(data):
        speaker = line.get("speaker", "Alex")
        text = line.get("text", "")
        
        if not text: continue
        
        # æ ¹æ“šå´é‚Šæ¬„é¸æ“‡çš„è²éŸ³
        voice = v_alex if speaker == "Alex" else v_jamie
        
        with NamedTemporaryFile(delete=False, suffix=".mp3") as f:
            temp_files.append(f.name)
            
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(text_to_speech_edge(text, voice, temp_files[-1]))
            loop.close()
            
            seg = AudioSegment.from_file(temp_files[-1])
            combined += seg + AudioSegment.silent(duration=300)
        except:
            pass
        
        my_bar.progress((i + 1) / total)

    for f in temp_files:
        try: os.remove(f)
        except: pass
        
    return combined

# --- ä¸»ä»‹é¢ Layout ---

st.markdown('<p class="main-header">ğŸ™ï¸ AI Podcast Studio</p>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">å°‡ä»»ä½•æ–‡ç« è½‰æ›ç‚ºç”Ÿå‹•çš„é›™äººå°è«‡</p>', unsafe_allow_html=True)

# æ­¥é©Ÿ 1: è¼¸å…¥èˆ‡è…³æœ¬ç”Ÿæˆ
col1, col2 = st.columns([2, 1])

with col1:
    url_input = st.text_input("ğŸ”— è²¼ä¸Šæ–‡ç« é€£çµ", placeholder="https://...")

with col2:
    st.write("") # Spacer
    st.write("") 
    generate_btn = st.button("âœ¨ ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆè…³æœ¬")

if generate_btn and url_input and openai_api_key:
    with st.spinner("æ­£åœ¨é–±è®€æ–‡ç« ä¸¦æ’°å¯«åŠ‡æœ¬..."):
        content = get_web_content(url_input)
        if content:
            script = generate_script(content)
            st.session_state.script_data = script
            st.session_state.audio_file = None # é‡ç½®èˆŠéŸ³æª”
        else:
            st.error("ç„¡æ³•è®€å–æ–‡ç« ")

# æ­¥é©Ÿ 2: è…³æœ¬é è¦½èˆ‡éŸ³è¨Šåˆæˆ (ä½¿ç”¨ Chat UI)
if st.session_state.script_data:
    st.divider()
    st.subheader("ğŸ“ è…³æœ¬é è¦½")
    
    # ä½¿ç”¨ Chat Message UI å‘ˆç¾å°è©±
    dialogue = []
    # è™•ç†å„ç¨® JSON å¯èƒ½çš„çµæ§‹
    raw_script = st.session_state.script_data
    if isinstance(raw_script, dict) and "dialogue" in raw_script:
        dialogue = raw_script["dialogue"]
    elif isinstance(raw_script, list):
        dialogue = raw_script
    else:
        dialogue = [raw_script]

    # è¿´åœˆé¡¯ç¤ºå°è©±
    for line in dialogue:
        speaker = line.get("speaker", "Alex")
        text = line.get("text", "")
        
        if speaker == "Alex":
            with st.chat_message("user", avatar="ğŸ‘¨â€ğŸ«"): # å°ˆå®¶é ­åƒ
                st.write(f"**Alex:** {text}")
        else:
            with st.chat_message("assistant", avatar="ğŸ™‹"): # å°ç™½é ­åƒ
                st.write(f"**Jamie:** {text}")

    st.divider()
    
    # æ­¥é©Ÿ 3: åˆæˆæŒ‰éˆ• (ç½®ä¸­)
    c1, c2, c3 = st.columns([1, 2, 1])
    with c2:
        start_audio_btn = st.button("ğŸ§ ç¬¬äºŒæ­¥ï¼šç¢ºèªè…³æœ¬ä¸¦åˆæˆèªéŸ³")

    if start_audio_btn:
        with st.spinner("æ­£åœ¨éŒ„éŸ³å®¤åˆæˆä¸­ (TTS)..."):
            final_audio = process_audio(st.session_state.script_data, alex_voice, jamie_voice)
            
            # å­˜åˆ° session state é¿å…é‡æ–°æ•´ç†å¾Œä¸è¦‹
            out_file = "podcast_final.mp3"
            final_audio.export(out_file, format="mp3")
            st.session_state.audio_file = out_file
            st.rerun() # é‡æ–°æ•´ç†é é¢ä»¥é¡¯ç¤ºæ’­æ”¾å™¨

# é¡¯ç¤ºæ’­æ”¾å™¨èˆ‡ä¸‹è¼‰
if st.session_state.audio_file:
    st.success("ğŸ‰ Podcast è£½ä½œå®Œæˆï¼")
    st.audio(st.session_state.audio_file)
    
    with open(st.session_state.audio_file, "rb") as f:
        st.download_button("ğŸ“¥ ä¸‹è¼‰ MP3", f, file_name="podcast.mp3")